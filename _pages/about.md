---
permalink: /
title: "Chiyu Ma"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year Ph.D. student in Computer Science at Dartmouth College, advised by Prof. [Soroush Vosoughi](https://www.cs.dartmouth.edu/~soroush//). My research focuses on trustworthy AI, with an emphasis on the interpretability of computer vision (CV) and natural language processing (NLP) models. I aim to design and develop intrinsically interpretable algorithms that enhance AI transparency and trustworthiness.
Prior to Dartmouth, I earned a Master's in Statistical Science from Duke University, where I was a member of the Interpretable Machine Learning Lab, advised by Prof. [Cynthia Rudin](https://users.cs.duke.edu/~cynthia/). I also collaborated with Prof. [Chaofan Chen](https://umaine.edu/scis/people/chaofan-chen/) from UMaine. Before that, I completed a B.S. in Statistics with honors from Carnegie Mellon University, concentrating in Computational Finance, and worked with Prof. [Zach Branson](https://sites.google.com/site/zjbranson/) on statistical analysis in biological applications.


Selected Publications
======
<div style="display: flex; align-items: center;">
    <div style="margin-right: 10px;">
        <img src="images/this_look_like_those_demo.png" alt="description" width="300"/>
    </div>
    <div>
        <h3><a href="https://neurips.cc/virtual/2023/poster/71040">This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations</a></h3>
        <p style="font-size: 9px;">We present ProtoConcepts, a method for interpretable image classification combining deep learning and case-based reasoning using prototypical parts. Existing
work in prototype-based image classification uses a “this looks like that” reasoning
process, which dissects a test image by finding prototypical parts and combining
evidence from these prototypes to make a final classification. However, all of the
existing prototypical part-based image classifiers provide only one-to-one comparisons, where a single training image patch serves as a prototype to compare with a
part of our test image. With these single-image comparisons, it can often be difficult
to identify the underlying concept being compared (e.g., “is it comparing the color
or the shape?”). Our proposed method modifies the architecture of prototype-based
networks to instead learn prototypical concepts which are visualized using multiple
image patches. Having multiple visualizations of the same prototype allows us to
more easily identify the concept captured by that prototype (e.g., “the test image
and the related training patches are all the same shade of blue”), and allows our
model to create richer, more interpretable visual explanations. Our experiments
show that our “this looks like those” reasoning process can be applied as a modification to a wide range of existing prototypical image classification networks while
achieving comparable accuracy on benchmark datasets.</p>
    </div>
</div>

Teaching
======
Duke Decison 618/521: Decision Analytics and Modeling TA: Fall 2021 <br>
Duke CS 617: Introduction to Machine Learning TA: Fall 2022 <br>
Dartmouth COSC 070: Foundations of Applied Computer Science TA: Fall 2023 <br>


Services
======
Reviewer: AAAI-AISI track 2023, TMLR 2024, ICML 2024, NeurIPS 2024, NeurIPS IAI workshop 2024, ICLR 2025 
